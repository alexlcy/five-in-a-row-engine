{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "0. Improve model to 50% accuracy\n",
    "1. Data Preprocessing (3 layer structure) [DONE]\n",
    "2. Data Preprocessing (5 layer structure)\n",
    "3. Building agent for the deep learning [Consider valid move]\n",
    "4. Reading the reinforcement learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from numba import jit\n",
    "import os\n",
    "import aim\n",
    "from aim.tensorflow import AimCallback \n",
    "from aim import Session\n",
    "from encoder.base import get_encoder_by_name\n",
    "encoder = get_encoder_by_name('layer_20_encoder', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127745, 8, 8)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_files_X = sorted([\"game_data/\" + file for file in os.listdir(\"game_data/\") if file.startswith(\"master_mat_rule\")])\n",
    "raw_X = np.concatenate([np.load(file) for file in mat_files_X])\n",
    "raw_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127745, 8, 8)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_files_Y = sorted([\"game_data/\" + file for file in os.listdir(\"game_data/\") if file.startswith(\"master_move_rule\")])\n",
    "raw_Y = np.concatenate([np.load(file) for file in mat_files_Y])\n",
    "raw_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = raw_X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.where(mat == 0)\n",
    "unvisited_node_list = list(zip(zeros[0], zeros[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., -1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., -1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  5,  6,  7,  8, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22,\n",
       "       23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def break_down_layers(game_state):\n",
    "    mat = np.copy(game_state)\n",
    "\n",
    "    master_X_open_self = []\n",
    "    master_X_open_oppo = []\n",
    "\n",
    "    for search_num in np.arange(4,0,-1):\n",
    "        X_open_self = np.zeros((8,8))\n",
    "        X_open_oppo = np.zeros((8,8))\n",
    "\n",
    "        # Did not consider open and close siutation\n",
    "        m = 8\n",
    "        n = 8\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                if j + search_num+1 <= m:\n",
    "                    sideway = mat[i][j:j+(search_num)]\n",
    "                    if np.sum(sideway) ==search_num:\n",
    "                        X_open_self[i][j:j+search_num] = 1\n",
    "                    if np.sum(sideway) == -search_num:\n",
    "                        X_open_oppo[i][j:j+search_num] = 1\n",
    "\n",
    "                if i + search_num+1 <= m:\n",
    "                    vert = mat[:,j][i:i+(search_num)]\n",
    "                    if np.sum(vert) == search_num:\n",
    "                        X_open_self[:,j][i:i+search_num] = 1\n",
    "                    if np.sum(vert) == -search_num:\n",
    "                        X_open_oppo[:,j][i:i+search_num] = 1\n",
    "\n",
    "                if j + search_num+1 <= m and i + search_num+1 <= n:\n",
    "                    diag = [mat[i+x][j+y] for x in range(search_num) for y in range(search_num) if x == y]\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_self[i+k][j+k] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_oppo[i+k][j+k] = 1\n",
    "\n",
    "                if j - search_num >= 0 and i + search_num+1 <= n:\n",
    "                    diag = [mat[i+x][j-y] for x in range(search_num) for y in range(search_num) if x == y]\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_self[i+k][j-k] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_oppo[i+k][j-k] = 1\n",
    "\n",
    "        i_axis = list(np.where(X_open_self==1)[0]) + list(np.where(X_open_oppo==1)[0])\n",
    "        j_axis = list(np.where(X_open_self==1)[1]) + list(np.where(X_open_oppo==1)[1])\n",
    "\n",
    "        for i,j in zip(i_axis, j_axis):\n",
    "            mat[i][j] = 0\n",
    "\n",
    "        master_X_open_self.append(np.copy(X_open_self))\n",
    "        master_X_open_oppo.append(np.copy(X_open_oppo))\n",
    "    return master_X_open_self + master_X_open_oppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No numba time: 13:52\n",
    "@jit()\n",
    "def potential_open_moves(game_state):\n",
    "\n",
    "    mat = np.copy(game_state)\n",
    "\n",
    "    master_X_open_self = []\n",
    "    master_X_open_oppo = []\n",
    "\n",
    "    for search_num in np.arange(4,1,-1):\n",
    "        X_open_self = np.zeros((8,8))\n",
    "        X_open_oppo = np.zeros((8,8))\n",
    "        X_record_self = np.zeros((8,8))\n",
    "        X_record_oppo = np.zeros((8,8))\n",
    "\n",
    "        # Did not consider open and close siutation\n",
    "        m = 8\n",
    "        n=8\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "\n",
    "                if j + search_num+1 <= m:\n",
    "                    sideway = mat[i][j:j+(search_num)]\n",
    "                    if np.sum(sideway) ==search_num:\n",
    "                        X_record_self[i][j:j+search_num] = 1\n",
    "\n",
    "                        if mat[i][j-1] == 0:\n",
    "                            X_open_self[i][j-1] = 1\n",
    "                        if  mat[i][j+(search_num)] == 0:\n",
    "                            X_open_self[i][j+(search_num)] = 1\n",
    "\n",
    "                    if np.sum(sideway) == -search_num:\n",
    "                        X_record_oppo[i][j:j+search_num] = 1\n",
    "\n",
    "                        if mat[i][j-1] == 0:\n",
    "                            X_open_oppo[i][j-1] = 1\n",
    "                        if  mat[i][j+(search_num)] == 0:\n",
    "                            X_open_oppo[i][j+(search_num)] = 1\n",
    "\n",
    "                if i + search_num+1 <= m:\n",
    "                    vert = mat[:,j][i:i+(search_num)]\n",
    "                    if np.sum(vert) == search_num:\n",
    "                        X_record_self[:,j][i:i+search_num] = 1\n",
    "\n",
    "                        if mat[i-1][j] == 0:\n",
    "                            X_open_self[i-1][j] = 1\n",
    "                        if mat[i+(search_num)][j] == 0:\n",
    "                            X_open_self[i+(search_num)][j] = 1\n",
    "\n",
    "                    if np.sum(vert) == -search_num:\n",
    "                        X_record_oppo[:,j][i:i+search_num] = 1\n",
    "\n",
    "                        if mat[i-1][j] == 0:\n",
    "                            X_open_oppo[i-1][j] = 1\n",
    "                        if mat[i+(search_num)][j] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j] = 1\n",
    "\n",
    "\n",
    "                if j + search_num+1 <= m and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j+y] for x in range(search_num) for y in range(search_num) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_self[i+k][j+k] = 1\n",
    "\n",
    "\n",
    "                        if mat[i-1][j-1] == 0:\n",
    "                            X_open_self[i-1][j-1] = 1\n",
    "                        if mat[i+(search_num)][j+(search_num)] == 0:\n",
    "                            X_open_self[i+(search_num)][j+(search_num)] = 1\n",
    "\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_oppo[i+k][j+k] = 1\n",
    "\n",
    "                        if mat[i-1][j-1] == 0:\n",
    "                            X_open_oppo[i-1][j-1] = 1\n",
    "                        if mat[i+(search_num)][j+(search_num)] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j+(search_num)] = 1\n",
    "\n",
    "                if j - search_num >= 0 and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j-y] for x in range(search_num) for y in range(search_num) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_self[i+k][j-k] = 1\n",
    "\n",
    "                        if mat[i-1][j+1] == 0:\n",
    "                            X_open_self[i-1][j-1] = 1\n",
    "                        if  mat[i+(search_num)][j-(search_num)] == 0:\n",
    "                            X_open_self[i+(search_num)][j-(search_num)] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_oppo[i+k][j-k] = 1\n",
    "\n",
    "\n",
    "                        if mat[i-1][j+1] == 0:\n",
    "                            X_open_oppo[i-1][j+1] = 1\n",
    "                        if mat[i+(search_num)][j-(search_num)] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j-(search_num)] = 1\n",
    "\n",
    "        i_axis = list(np.where(X_record_self==1)[0]) + list(np.where(X_record_oppo==1)[0])\n",
    "        j_axis = list(np.where(X_record_self==1)[1]) + list(np.where(X_record_oppo==1)[1])\n",
    "\n",
    "        for i,j in zip(i_axis, j_axis):\n",
    "            mat[i][j] = 0\n",
    "\n",
    "        master_X_open_self.append(np.copy(X_open_self))\n",
    "        master_X_open_oppo.append(np.copy(X_open_oppo))\n",
    "    return master_X_open_self + master_X_open_oppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(raw_X, raw_Y):\n",
    "    total_X = []\n",
    "    for i in tqdm(range(1, len(raw_X))):\n",
    "        input_X = raw_X[i]\n",
    "        layer_my_move = np.array(input_X > 0).astype(int)\n",
    "        layer_oppo_move = np.array(input_X < 0).astype(int)\n",
    "        layer_valid_move = np.array(input_X == 0).astype(int)\n",
    "        #layers_break_down = break_down_layers(input_X)\n",
    "        layers_open_moves = potential_open_moves(input_X)\n",
    "        layer_last_move = raw_Y[i-1]\n",
    "        layer_zeros = np.zeros((8,8))\n",
    "        layer_ones = np.ones((8,8))\n",
    "        final_X = np.dstack([layer_my_move, layer_oppo_move, layer_last_move, layer_valid_move+layer_zeros+layer_ones] + layers_open_moves)\n",
    "        final_X = np.expand_dims(final_X, axis = 0)\n",
    "        total_X.append(final_X)\n",
    "    X = np.vstack(total_X)\n",
    "    Y = raw_Y[1:]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009b4aca679940b4a88fc6482c124877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127744.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-5b02bfa81ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-161-ab3affa0d954>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(raw_X, raw_Y)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlayer_oppo_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_X\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlayer_valid_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_X\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mlayers_break_down\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreak_down_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m#layers_break_down = potential_open_moves(input_X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlayer_last_move\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X,Y = preprocess_data(raw_X, raw_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 8, 8, 10)\n",
      "(61878, 8, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "X,Y = shuffle(X,Y)\n",
    "X_train = X[:int(len(X)*0.8)]\n",
    "X_test = X[int(len(X)*0.8):]\n",
    "Y_train = Y[:int(len(X)*0.8)]\n",
    "Y_test = Y[int(len(X)*0.8):]\n",
    "print(X_train.shape)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 64)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],64)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, data_directory, samples):\n",
    "        self.data_directory = data_directory\n",
    "        self.samples = samples\n",
    "        self.files = set(file_name for file_name, index in samples)    1\n",
    "        self.num_samples = None\n",
    "\n",
    "    def get_num_samples(self, batch_size=128, num_classes=19 * 19):    2\n",
    "        if self.num_samples is not None:\n",
    "            return self.num_samples\n",
    "        else:\n",
    "            self.num_samples = 0\n",
    "            for X, y in self._generate(batch_size=batch_size,\n",
    "                                       num_classes=num_classes):\n",
    "                self.num_samples += X.shape[0]\n",
    "            return self.num_samples\n",
    "        \n",
    "    def _generate(self, batch_size, num_classes):\n",
    "        for zip_file_name in self.files:\n",
    "            file_name = zip_file_name.replace('.tar.gz', '') + 'train'\n",
    "            base = self.data_directory + '/' + file_name + '_features_*.npy'\n",
    "            for feature_file in glob.glob(base):\n",
    "                label_file = feature_file.replace('features', 'labels')\n",
    "                x = np.load(feature_file)\n",
    "                y = np.load(label_file)\n",
    "                x = x.astype('float32')\n",
    "                y = to_categorical(y.astype(int), num_classes)\n",
    "                while x.shape[0] >= batch_size:\n",
    "                    x_batch, x = x[:batch_size], x[batch_size:]\n",
    "                    y_batch, y = y[:batch_size], y[batch_size:]\n",
    "                    yield x_batch, y_batch    \n",
    "                    \n",
    "    def generate(self, batch_size=128, num_classes=19 * 19):\n",
    "        while True:\n",
    "            for item in self._generate(batch_size, num_classes):\n",
    "                yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45853, 8, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "#X_train = X_train.reshape(X_train.shape[0],8,8,1)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 64)\n",
    "#X_test = X_test.reshape(X_test.shape[0],8,8,1)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],64)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GomokuNet(tf.keras.Model):\n",
    "    def __init__(self,nums_class=64):\n",
    "        super(GomokuNet,self).__init__()\n",
    "        self.model = tf.keras.layers.Conv2D(48,(3,3), input_shape=(8,8,10),strides=(1,1))\n",
    "        self.res_layer_1 = self.ResNet_build(48, 2, strides=1)\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc_model = tf.keras.layers.Dense(nums_class)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.model(inputs)\n",
    "        x = self.res_layer_1(x)\n",
    "        x = self.avg_pool(x) \n",
    "        x = self.fc_model(x)\n",
    "        return x\n",
    "    \n",
    "    def res_net_block(input_data, filters, conv_size):\n",
    "        x = tf.keras.layers.Conv2D(filters, conv_size, activation='relu', padding='same')(input_data)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Add()([x, input_data])\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    def ResNet_build(self,filter_nums,block_nums,strides=1):\n",
    "        build_model = tf.keras.models.Sequential()\n",
    "        build_model.add(ResBlock(filter_nums,strides))\n",
    "        for _ in range(1,block_nums):\n",
    "            build_model.add(ResBlock(filter_nums,strides=1))\n",
    "        return build_model\n",
    "    \n",
    "\n",
    "class ResBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filter_nums, strides=1, residual_path=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(filter_nums,(3,3),strides=strides,padding='same')\n",
    "        self.bn_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_relu = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(filter_nums,(3,3),strides=1,padding='same')\n",
    "        self.bn_2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        if strides !=1:\n",
    "            self.block = tf.keras.models.Sequential()\n",
    "            self.block.add(tf.keras.layers.Conv2D(filter_nums,(1,1),strides=strides))\n",
    "        else:\n",
    "            self.block = lambda x:x\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x, training=training)\n",
    "        x = self.act_relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x,training=training)\n",
    "\n",
    "        identity = self.block(inputs)\n",
    "        outputs = tf.keras.layers.add([x,identity])\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_session = Session(experiment='Gomuko-4planes-6layers-normalshape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GomokuNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (4,4), activation='relu', input_shape=(8,8,10), padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (4,4), activation='relu',  padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', ddpadding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    #The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "#     # 512 neuron hidden layer\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "    \n",
    "    # Last layer of model\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "242/242 [==============================] - 54s 221ms/step - loss: 4.1190 - accuracy: 0.0412 - val_loss: 4.1153 - val_accuracy: 0.0291\n",
      "Epoch 2/30\n",
      "242/242 [==============================] - 52s 213ms/step - loss: 3.7396 - accuracy: 0.1176 - val_loss: 3.4165 - val_accuracy: 0.1688\n",
      "Epoch 3/30\n",
      "242/242 [==============================] - 51s 213ms/step - loss: 3.2820 - accuracy: 0.2001 - val_loss: 2.9351 - val_accuracy: 0.2614\n",
      "Epoch 4/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 2.8900 - accuracy: 0.2625 - val_loss: 2.5409 - val_accuracy: 0.3017\n",
      "Epoch 5/30\n",
      "242/242 [==============================] - 52s 213ms/step - loss: 2.6043 - accuracy: 0.3160 - val_loss: 2.3684 - val_accuracy: 0.3448\n",
      "Epoch 6/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 2.3652 - accuracy: 0.3630 - val_loss: 2.1358 - val_accuracy: 0.3680\n",
      "Epoch 7/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 2.1951 - accuracy: 0.3933 - val_loss: 2.1747 - val_accuracy: 0.3846\n",
      "Epoch 8/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 2.0662 - accuracy: 0.4210 - val_loss: 2.0393 - val_accuracy: 0.3977\n",
      "Epoch 9/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 1.9663 - accuracy: 0.4395 - val_loss: 1.9795 - val_accuracy: 0.3965\n",
      "Epoch 10/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.8700 - accuracy: 0.4653 - val_loss: 1.9864 - val_accuracy: 0.3975\n",
      "Epoch 11/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.7927 - accuracy: 0.4820 - val_loss: 2.1278 - val_accuracy: 0.3961\n",
      "Epoch 12/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.7219 - accuracy: 0.4975 - val_loss: 2.0413 - val_accuracy: 0.4028\n",
      "Epoch 13/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.6534 - accuracy: 0.5167 - val_loss: 2.5075 - val_accuracy: 0.3846\n",
      "Epoch 14/30\n",
      "242/242 [==============================] - 52s 213ms/step - loss: 1.5991 - accuracy: 0.5311 - val_loss: 2.0583 - val_accuracy: 0.3998\n",
      "Epoch 15/30\n",
      "242/242 [==============================] - 51s 212ms/step - loss: 1.5512 - accuracy: 0.5431 - val_loss: 2.1203 - val_accuracy: 0.3778\n",
      "Epoch 16/30\n",
      "242/242 [==============================] - 52s 213ms/step - loss: 1.5013 - accuracy: 0.5551 - val_loss: 2.2614 - val_accuracy: 0.4020\n",
      "Epoch 17/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 1.4538 - accuracy: 0.5645 - val_loss: 2.1349 - val_accuracy: 0.4001\n",
      "Epoch 18/30\n",
      "242/242 [==============================] - 53s 217ms/step - loss: 1.4516 - accuracy: 0.5731 - val_loss: 2.2644 - val_accuracy: 0.3926\n",
      "Epoch 19/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.4089 - accuracy: 0.5885 - val_loss: 2.5625 - val_accuracy: 0.3878\n",
      "Epoch 20/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.3565 - accuracy: 0.5954 - val_loss: 2.2314 - val_accuracy: 0.4030\n",
      "Epoch 21/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 1.3440 - accuracy: 0.6062 - val_loss: 2.6566 - val_accuracy: 0.4106\n",
      "Epoch 22/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.3046 - accuracy: 0.6099 - val_loss: 2.5617 - val_accuracy: 0.4081\n",
      "Epoch 23/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.3090 - accuracy: 0.6196 - val_loss: 2.3302 - val_accuracy: 0.4097\n",
      "Epoch 24/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.2505 - accuracy: 0.6286 - val_loss: 2.2990 - val_accuracy: 0.4008\n",
      "Epoch 25/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.2236 - accuracy: 0.6390 - val_loss: 2.2433 - val_accuracy: 0.4048\n",
      "Epoch 26/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.1791 - accuracy: 0.6435 - val_loss: 3.0798 - val_accuracy: 0.3994\n",
      "Epoch 27/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.1536 - accuracy: 0.6511 - val_loss: 2.3325 - val_accuracy: 0.3948\n",
      "Epoch 28/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.1645 - accuracy: 0.6613 - val_loss: 2.5290 - val_accuracy: 0.4020\n",
      "Epoch 29/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.1075 - accuracy: 0.6629 - val_loss: 2.9861 - val_accuracy: 0.4050\n",
      "Epoch 30/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.0951 - accuracy: 0.6698 - val_loss: 3.0628 - val_accuracy: 0.4050\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train, \n",
    "                    epochs=30,\n",
    "                    batch_size=256,\n",
    "                    validation_data = (X_test, Y_test), \n",
    "                    verbose = 1, \n",
    "                   #callbacks=[AimCallback(aim_session)]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tempfile\n",
    "import keras_util\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from encoder.base import get_encoder_by_name\n",
    "encoder = get_encoder_by_name('allpattern', 8)\n",
    "from tensorflow.keras.models import load_model, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"experiment_2020_12_22_06_29_50\", 'r+') as f:\n",
    "    state = np.array(f['experience']['states'])\n",
    "    action = np.array(f['experience']['actions'])\n",
    "    reward = np.array(f['experience']['rewards'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = np.where(reward == 0.2, -0.1,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"experience_data/experiment_updated\", 'w') as f:\n",
    "    f.create_group('experience')\n",
    "    f['experience'].create_dataset('states', data=state_updated)\n",
    "    f['experience'].create_dataset('actions', data=action_updated)\n",
    "    f['experience'].create_dataset('rewards', data=reward_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training value network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"experiment_2020_12_22_06_29_50\", 'r+') as f:\n",
    "    state = np.array(f['experience']['states'])\n",
    "    reward = np.array(f['experience']['rewards'])   \n",
    "    \n",
    "win_lose_index = np.where(reward != 0.2)\n",
    "state = state[win_lose_index]\n",
    "reward = reward[win_lose_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "state,reward = shuffle(state, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.squeeze(state, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = state[:int(len(state)*0.8)]\n",
    "X_test = state[int(len(state)*0.8):]\n",
    "reward_train = reward[:int(len(state)*0.8)]\n",
    "reward_test = reward[int(len(state)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (5,5), activation='relu', input_shape=(8,8,20), padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (5,5), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (4,4), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(1, (2,2), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Last layer of model\n",
    "    tf.keras.layers.Dense(1, activation='tanh')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "271/271 [==============================] - 53s 194ms/step - loss: 0.8686 - val_loss: 0.9144\n",
      "Epoch 2/30\n",
      "271/271 [==============================] - 52s 190ms/step - loss: 0.5584 - val_loss: 0.5364\n",
      "Epoch 3/30\n",
      "271/271 [==============================] - 52s 192ms/step - loss: 0.4204 - val_loss: 0.4760\n",
      "Epoch 4/30\n",
      "271/271 [==============================] - 53s 195ms/step - loss: 0.3598 - val_loss: 0.4131\n",
      "Epoch 5/30\n",
      "271/271 [==============================] - 53s 194ms/step - loss: 0.3126 - val_loss: 0.4070\n",
      "Epoch 6/30\n",
      "271/271 [==============================] - 53s 194ms/step - loss: 0.2785 - val_loss: 0.3963\n",
      "Epoch 7/30\n",
      "271/271 [==============================] - 53s 194ms/step - loss: 0.2628 - val_loss: 0.3887\n",
      "Epoch 8/30\n",
      "271/271 [==============================] - 51s 187ms/step - loss: 0.2452 - val_loss: 0.3652\n",
      "Epoch 9/30\n",
      "271/271 [==============================] - 50s 185ms/step - loss: 0.2315 - val_loss: 0.3511\n",
      "Epoch 10/30\n",
      "271/271 [==============================] - 50s 186ms/step - loss: 0.2161 - val_loss: 0.3293\n",
      "Epoch 11/30\n",
      "271/271 [==============================] - 51s 187ms/step - loss: 0.2083 - val_loss: 0.3445\n"
     ]
    }
   ],
   "source": [
    "Early_Stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(loss = 'mse', \n",
    "              optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train,reward_train, \n",
    "                    epochs=30,\n",
    "                    batch_size=256,\n",
    "                    validation_data = (X_test, reward_test), \n",
    "                    verbose = 1, \n",
    "                    callbacks=[Early_Stopping_callback]\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alexlo/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/alexlo/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: alpha_gomuku_value_net_no_draw/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"alpha_gomuku_value_net_no_draw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"experience_data/experiment_2020_12_24_00_41_57\", 'r+') as f:\n",
    "    raw_state = np.array(f['experience']['raw_states'])\n",
    "    state = np.array(f['experience']['states'])\n",
    "    action = np.array(f['experience']['actions'])\n",
    "    reward = np.array(f['experience']['rewards'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_state[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  0., -1.,  0.,  0.,  0.],\n",
       "       [ 0., -1.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  0., -1.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -1., -1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0., -1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_state[292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1. , -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. ,\n",
       "       -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. ,\n",
       "       -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -1. , -1. , -1. , -1. ,\n",
       "       -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. ,\n",
       "       -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. , -1. ,\n",
       "       -1. , -1. , -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,\n",
       "       -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3, -0.3,  1. ,  1. ,  1. ,\n",
       "        1. ,  1. ,  1. ,  1. ,  1. ,  1. ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward[292:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
