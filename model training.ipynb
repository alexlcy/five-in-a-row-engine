{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n",
    "\n",
    "0. Improve model to 50% accuracy\n",
    "1. Data Preprocessing (3 layer structure) [DONE]\n",
    "2. Data Preprocessing (5 layer structure)\n",
    "3. Building agent for the deep learning [Consider valid move]\n",
    "4. Reading the reinforcement learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from numba import jit\n",
    "import os\n",
    "import aim\n",
    "from aim.tensorflow import AimCallback \n",
    "from aim import Session\n",
    "from encoder.base import get_encoder_by_name\n",
    "encoder = get_encoder_by_name('layer_20_encoder', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files_X = sorted([\"game_data/\" + file for file in os.listdir(\"game_data/\") if file.startswith(\"master_mat_rule\")])\n",
    "raw_X = np.concatenate([np.load(file) for file in mat_files_X])\n",
    "raw_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files_Y = sorted([\"game_data/\" + file for file in os.listdir(\"game_data/\") if file.startswith(\"master_move_rule\")])\n",
    "raw_Y = np.concatenate([np.load(file) for file in mat_files_Y])\n",
    "raw_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = raw_X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.where(mat == 0)\n",
    "unvisited_node_list = list(zip(zeros[0], zeros[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def break_down_layers(game_state):\n",
    "    mat = np.copy(game_state)\n",
    "\n",
    "    master_X_open_self = []\n",
    "    master_X_open_oppo = []\n",
    "\n",
    "    for search_num in np.arange(4,0,-1):\n",
    "        X_open_self = np.zeros((8,8))\n",
    "        X_open_oppo = np.zeros((8,8))\n",
    "\n",
    "        # Did not consider open and close siutation\n",
    "        m = 8\n",
    "        n = 8\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                if j + search_num+1 <= m:\n",
    "                    sideway = mat[i][j:j+(search_num)]\n",
    "                    if np.sum(sideway) ==search_num:\n",
    "                        X_open_self[i][j:j+search_num] = 1\n",
    "                    if np.sum(sideway) == -search_num:\n",
    "                        X_open_oppo[i][j:j+search_num] = 1\n",
    "\n",
    "                if i + search_num+1 <= m:\n",
    "                    vert = mat[:,j][i:i+(search_num)]\n",
    "                    if np.sum(vert) == search_num:\n",
    "                        X_open_self[:,j][i:i+search_num] = 1\n",
    "                    if np.sum(vert) == -search_num:\n",
    "                        X_open_oppo[:,j][i:i+search_num] = 1\n",
    "\n",
    "                if j + search_num+1 <= m and i + search_num+1 <= n:\n",
    "                    diag = [mat[i+x][j+y] for x in range(search_num) for y in range(search_num) if x == y]\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_self[i+k][j+k] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_oppo[i+k][j+k] = 1\n",
    "\n",
    "                if j - search_num >= 0 and i + search_num+1 <= n:\n",
    "                    diag = [mat[i+x][j-y] for x in range(search_num) for y in range(search_num) if x == y]\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_self[i+k][j-k] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_oppo[i+k][j-k] = 1\n",
    "\n",
    "        i_axis = list(np.where(X_open_self==1)[0]) + list(np.where(X_open_oppo==1)[0])\n",
    "        j_axis = list(np.where(X_open_self==1)[1]) + list(np.where(X_open_oppo==1)[1])\n",
    "\n",
    "        for i,j in zip(i_axis, j_axis):\n",
    "            mat[i][j] = 0\n",
    "\n",
    "        master_X_open_self.append(np.copy(X_open_self))\n",
    "        master_X_open_oppo.append(np.copy(X_open_oppo))\n",
    "    return master_X_open_self + master_X_open_oppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No numba time: 13:52\n",
    "@jit()\n",
    "def potential_open_moves(game_state):\n",
    "\n",
    "    mat = np.copy(game_state)\n",
    "\n",
    "    master_X_open_self = []\n",
    "    master_X_open_oppo = []\n",
    "\n",
    "    for search_num in np.arange(4,1,-1):\n",
    "        X_open_self = np.zeros((8,8))\n",
    "        X_open_oppo = np.zeros((8,8))\n",
    "        X_record_self = np.zeros((8,8))\n",
    "        X_record_oppo = np.zeros((8,8))\n",
    "\n",
    "        # Did not consider open and close siutation\n",
    "        m = 8\n",
    "        n=8\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "\n",
    "                if j + search_num+1 <= m:\n",
    "                    sideway = mat[i][j:j+(search_num)]\n",
    "                    if np.sum(sideway) ==search_num:\n",
    "                        X_record_self[i][j:j+search_num] = 1\n",
    "\n",
    "                        if mat[i][j-1] == 0:\n",
    "                            X_open_self[i][j-1] = 1\n",
    "                        if  mat[i][j+(search_num)] == 0:\n",
    "                            X_open_self[i][j+(search_num)] = 1\n",
    "\n",
    "                    if np.sum(sideway) == -search_num:\n",
    "                        X_record_oppo[i][j:j+search_num] = 1\n",
    "\n",
    "                        if mat[i][j-1] == 0:\n",
    "                            X_open_oppo[i][j-1] = 1\n",
    "                        if  mat[i][j+(search_num)] == 0:\n",
    "                            X_open_oppo[i][j+(search_num)] = 1\n",
    "\n",
    "                if i + search_num+1 <= m:\n",
    "                    vert = mat[:,j][i:i+(search_num)]\n",
    "                    if np.sum(vert) == search_num:\n",
    "                        X_record_self[:,j][i:i+search_num] = 1\n",
    "\n",
    "                        if mat[i-1][j] == 0:\n",
    "                            X_open_self[i-1][j] = 1\n",
    "                        if mat[i+(search_num)][j] == 0:\n",
    "                            X_open_self[i+(search_num)][j] = 1\n",
    "\n",
    "                    if np.sum(vert) == -search_num:\n",
    "                        X_record_oppo[:,j][i:i+search_num] = 1\n",
    "\n",
    "                        if mat[i-1][j] == 0:\n",
    "                            X_open_oppo[i-1][j] = 1\n",
    "                        if mat[i+(search_num)][j] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j] = 1\n",
    "\n",
    "\n",
    "                if j + search_num+1 <= m and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j+y] for x in range(search_num) for y in range(search_num) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_self[i+k][j+k] = 1\n",
    "\n",
    "\n",
    "                        if mat[i-1][j-1] == 0:\n",
    "                            X_open_self[i-1][j-1] = 1\n",
    "                        if mat[i+(search_num)][j+(search_num)] == 0:\n",
    "                            X_open_self[i+(search_num)][j+(search_num)] = 1\n",
    "\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_oppo[i+k][j+k] = 1\n",
    "\n",
    "                        if mat[i-1][j-1] == 0:\n",
    "                            X_open_oppo[i-1][j-1] = 1\n",
    "                        if mat[i+(search_num)][j+(search_num)] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j+(search_num)] = 1\n",
    "\n",
    "                if j - search_num >= 0 and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j-y] for x in range(search_num) for y in range(search_num) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_self[i+k][j-k] = 1\n",
    "\n",
    "                        if mat[i-1][j+1] == 0:\n",
    "                            X_open_self[i-1][j-1] = 1\n",
    "                        if  mat[i+(search_num)][j-(search_num)] == 0:\n",
    "                            X_open_self[i+(search_num)][j-(search_num)] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_oppo[i+k][j-k] = 1\n",
    "\n",
    "\n",
    "                        if mat[i-1][j+1] == 0:\n",
    "                            X_open_oppo[i-1][j+1] = 1\n",
    "                        if mat[i+(search_num)][j-(search_num)] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j-(search_num)] = 1\n",
    "\n",
    "        i_axis = list(np.where(X_record_self==1)[0]) + list(np.where(X_record_oppo==1)[0])\n",
    "        j_axis = list(np.where(X_record_self==1)[1]) + list(np.where(X_record_oppo==1)[1])\n",
    "\n",
    "        for i,j in zip(i_axis, j_axis):\n",
    "            mat[i][j] = 0\n",
    "\n",
    "        master_X_open_self.append(np.copy(X_open_self))\n",
    "        master_X_open_oppo.append(np.copy(X_open_oppo))\n",
    "    return master_X_open_self + master_X_open_oppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(raw_X, raw_Y):\n",
    "    total_X = []\n",
    "    for i in tqdm(range(1, len(raw_X))):\n",
    "        input_X = raw_X[i]\n",
    "        layer_my_move = np.array(input_X > 0).astype(int)\n",
    "        layer_oppo_move = np.array(input_X < 0).astype(int)\n",
    "        layer_valid_move = np.array(input_X == 0).astype(int)\n",
    "        #layers_break_down = break_down_layers(input_X)\n",
    "        layers_open_moves = potential_open_moves(input_X)\n",
    "        layer_last_move = raw_Y[i-1]\n",
    "        layer_zeros = np.zeros((8,8))\n",
    "        layer_ones = np.ones((8,8))\n",
    "        final_X = np.dstack([layer_my_move, layer_oppo_move, layer_last_move, layer_valid_move+layer_zeros+layer_ones] + layers_open_moves)\n",
    "        final_X = np.expand_dims(final_X, axis = 0)\n",
    "        total_X.append(final_X)\n",
    "    X = np.vstack(total_X)\n",
    "    Y = raw_Y[1:]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = preprocess_data(raw_X, raw_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = shuffle(X,Y)\n",
    "X_train = X[:int(len(X)*0.8)]\n",
    "X_test = X[int(len(X)*0.8):]\n",
    "Y_train = Y[:int(len(X)*0.8)]\n",
    "Y_test = Y[int(len(X)*0.8):]\n",
    "print(X_train.shape)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 64)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],64)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, data_directory, samples):\n",
    "        self.data_directory = data_directory\n",
    "        self.samples = samples\n",
    "        self.files = set(file_name for file_name, index in samples)    1\n",
    "        self.num_samples = None\n",
    "\n",
    "    def get_num_samples(self, batch_size=128, num_classes=19 * 19):    2\n",
    "        if self.num_samples is not None:\n",
    "            return self.num_samples\n",
    "        else:\n",
    "            self.num_samples = 0\n",
    "            for X, y in self._generate(batch_size=batch_size,\n",
    "                                       num_classes=num_classes):\n",
    "                self.num_samples += X.shape[0]\n",
    "            return self.num_samples\n",
    "        \n",
    "    def _generate(self, batch_size, num_classes):\n",
    "        for zip_file_name in self.files:\n",
    "            file_name = zip_file_name.replace('.tar.gz', '') + 'train'\n",
    "            base = self.data_directory + '/' + file_name + '_features_*.npy'\n",
    "            for feature_file in glob.glob(base):\n",
    "                label_file = feature_file.replace('features', 'labels')\n",
    "                x = np.load(feature_file)\n",
    "                y = np.load(label_file)\n",
    "                x = x.astype('float32')\n",
    "                y = to_categorical(y.astype(int), num_classes)\n",
    "                while x.shape[0] >= batch_size:\n",
    "                    x_batch, x = x[:batch_size], x[batch_size:]\n",
    "                    y_batch, y = y[:batch_size], y[batch_size:]\n",
    "                    yield x_batch, y_batch    \n",
    "                    \n",
    "    def generate(self, batch_size=128, num_classes=19 * 19):\n",
    "        while True:\n",
    "            for item in self._generate(batch_size, num_classes):\n",
    "                yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.reshape(X_train.shape[0],8,8,1)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 64)\n",
    "#X_test = X_test.reshape(X_test.shape[0],8,8,1)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],64)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GomokuNet(tf.keras.Model):\n",
    "    def __init__(self,nums_class=64):\n",
    "        super(GomokuNet,self).__init__()\n",
    "        self.model = tf.keras.layers.Conv2D(48,(3,3), input_shape=(8,8,10),strides=(1,1))\n",
    "        self.res_layer_1 = self.ResNet_build(48, 2, strides=1)\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc_model = tf.keras.layers.Dense(nums_class)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.model(inputs)\n",
    "        x = self.res_layer_1(x)\n",
    "        x = self.avg_pool(x) \n",
    "        x = self.fc_model(x)\n",
    "        return x\n",
    "    \n",
    "    def res_net_block(input_data, filters, conv_size):\n",
    "        x = tf.keras.layers.Conv2D(filters, conv_size, activation='relu', padding='same')(input_data)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Add()([x, input_data])\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    def ResNet_build(self,filter_nums,block_nums,strides=1):\n",
    "        build_model = tf.keras.models.Sequential()\n",
    "        build_model.add(ResBlock(filter_nums,strides))\n",
    "        for _ in range(1,block_nums):\n",
    "            build_model.add(ResBlock(filter_nums,strides=1))\n",
    "        return build_model\n",
    "    \n",
    "\n",
    "class ResBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filter_nums, strides=1, residual_path=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(filter_nums,(3,3),strides=strides,padding='same')\n",
    "        self.bn_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_relu = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(filter_nums,(3,3),strides=1,padding='same')\n",
    "        self.bn_2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        if strides !=1:\n",
    "            self.block = tf.keras.models.Sequential()\n",
    "            self.block.add(tf.keras.layers.Conv2D(filter_nums,(1,1),strides=strides))\n",
    "        else:\n",
    "            self.block = lambda x:x\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x, training=training)\n",
    "        x = self.act_relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x,training=training)\n",
    "\n",
    "        identity = self.block(inputs)\n",
    "        outputs = tf.keras.layers.add([x,identity])\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_session = Session(experiment='Gomuko-4planes-6layers-normalshape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GomokuNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (4,4), activation='relu', input_shape=(8,8,10), padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (4,4), activation='relu',  padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', ddpadding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    #The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "#     # 512 neuron hidden layer\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "    \n",
    "    # Last layer of model\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train, \n",
    "                    epochs=30,\n",
    "                    batch_size=256,\n",
    "                    validation_data = (X_test, Y_test), \n",
    "                    verbose = 1, \n",
    "                   #callbacks=[AimCallback(aim_session)]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tempfile\n",
    "import keras_util\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from encoder.base import get_encoder_by_name\n",
    "encoder = get_encoder_by_name('allpattern', 8)\n",
    "from tensorflow.keras.models import load_model, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"experiment_2020_12_22_06_29_50\", 'r+') as f:\n",
    "    state = np.array(f['experience']['states'])\n",
    "    action = np.array(f['experience']['actions'])\n",
    "    reward = np.array(f['experience']['rewards'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = np.where(reward == 0.2, -0.1,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"experience_data/experiment_updated\", 'w') as f:\n",
    "    f.create_group('experience')\n",
    "    f['experience'].create_dataset('states', data=state_updated)\n",
    "    f['experience'].create_dataset('actions', data=action_updated)\n",
    "    f['experience'].create_dataset('rewards', data=reward_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training value network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"experiment_2020_12_22_06_29_50\", 'r+') as f:\n",
    "    state = np.array(f['experience']['states'])\n",
    "    reward = np.array(f['experience']['rewards'])   \n",
    "    \n",
    "win_lose_index = np.where(reward != 0.2)\n",
    "state = state[win_lose_index]\n",
    "reward = reward[win_lose_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "state,reward = shuffle(state, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.squeeze(state, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = state[:int(len(state)*0.8)]\n",
    "X_test = state[int(len(state)*0.8):]\n",
    "reward_train = reward[:int(len(state)*0.8)]\n",
    "reward_test = reward[int(len(state)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (5,5), activation='relu', input_shape=(8,8,20), padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (5,5), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (4,4), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(1, (2,2), activation='relu', padding = 'same'),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    # Last layer of model\n",
    "    tf.keras.layers.Dense(1, activation='tanh')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Early_Stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(loss = 'mse', \n",
    "              optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train,reward_train, \n",
    "                    epochs=30,\n",
    "                    batch_size=256,\n",
    "                    validation_data = (X_test, reward_test), \n",
    "                    verbose = 1, \n",
    "                    callbacks=[Early_Stopping_callback]\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"alpha_gomuku_value_net_no_draw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the problems:\n",
    "1. No draw hanlding will distort the order (Rejected. Checked both 1 lose to -1 and -1 lose to 1) <br>\n",
    "2. Shouldnt pre-set starting position <br>\n",
    "3. Something wrong with -1 (Rejected. Checked the -1 situation for 1 lose to -1 and -1 lose to 1) <br>\n",
    "4. Wrong setting of learning rate and batch size \n",
    "5. Learning rate is too large\n",
    "6. Batch size is too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_data/experiment_no_draw_experiment_2020_12_26_07_21_53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"experiment_no_draw_experiment_2020_12_26_07_21_53\", 'r+') as f:\n",
    "    raw_state = np.array(f['experience']['raw_states'])\n",
    "    state = np.array(f['experience']['states'])\n",
    "    action = np.array(f['experience']['actions'])\n",
    "    reward = np.array(f['experience']['rewards'])    \n",
    "    advantage = np.array(f['experience']['advantages']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.array(\n",
    "      [[ 1., -1., -1.,  1., -1.,  1., -1.,  1.],\n",
    "       [-1.,  1., -1.,  1., -1.,  1., -1.,  1.],\n",
    "       [-1.,  1., -1.,  1.,  1., -1., -1.,  1.],\n",
    "       [-1., -1.,  1., -1.,  1.,  1.,  1.,  1.],\n",
    "       [ 1., -1.,  1.,  1., -1.,  1., -1., -1.],\n",
    "       [ 1.,  1., -1.,  0., -1.,  1.,  1., -1.],\n",
    "       [ 1., -1., -1., -1.,  1., -1., -1., -1.],\n",
    "       [ -1.,  1., -1., -1.,  1., -1.,  1.,  1.]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_for_done(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10000):\n",
    "    if check_for_done(raw_state[i])[0] is True:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_done(mat):\n",
    "    \"\"\"\n",
    "    please write your own code testing if the game is over. Return a boolean variable done. If one of the players wins\n",
    "    or the tie happens, return True. Otherwise return False. Print a message about the result of the game.\n",
    "    input:\n",
    "        2D matrix representing the state of the game\n",
    "    output:\n",
    "        none\n",
    "    \"\"\"\n",
    "    m, n = mat.shape\n",
    "    target1 = [1, 1, 1, 1, 1]\n",
    "    target2 = [-1, -1, -1, -1, -1]\n",
    "    if len(np.where(mat == 0)[0]) == 0:\n",
    "        return True, 0.5\n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if j + 5 <= m:\n",
    "                sideway = mat[i][j:j + 5]\n",
    "                if (sideway == target1).all():\n",
    "                    return True, 1\n",
    "                if (sideway == target2).all():\n",
    "                    return True, -1\n",
    "            if i + 5 <= m:\n",
    "                vert = mat[:, j][i:i + 5]\n",
    "                if (vert == target1).all():\n",
    "                    return True, 1\n",
    "                if (vert == target2).all():\n",
    "                    return True, -1\n",
    "            if j + 5 <= m and i + 5 <= n:\n",
    "                diag = [mat[i + x][j + y] for x in range(5) for y in range(5) if x == y]\n",
    "                if diag == target1:\n",
    "                    return True, 1\n",
    "                if diag == target2:\n",
    "                    return True, -1\n",
    "            if j - 4 >= 0 and i + 5 <= n:\n",
    "                diag = [mat[i + x][j - y] for x in range(5) for y in range(5) if x == y]\n",
    "                if diag == target1:\n",
    "                    return True, 1\n",
    "                if diag == target2:\n",
    "                    return True, -1\n",
    "    return False, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"experience_data/experiment_no_draw_experiment_2020_12_26_07_21_53\", 'r+') as f:\n",
    "    raw_state = np.array(f['experience']['raw_states'])\n",
    "    state = np.array(f['experience']['states'])\n",
    "    action = np.array(f['experience']['actions'])\n",
    "    reward = np.array(f['experience']['rewards'])    \n",
    "    advantage = np.array(f['experience']['advantages']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_raw_state = raw_state\n",
    "master_state = state\n",
    "master_action = action\n",
    "master_reward = reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"experiment_no_draw_experiment_2020_12_26_07_21_58\",\n",
    "       \"experiment_no_draw_experiment_2020_12_26_07_22_25\",\n",
    "       \"experiment_no_draw_experiment_2020_12_26_07_22_54\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with h5py.File(f\"experience_data/{file}\", 'r+') as f:\n",
    "        raw_state = np.array(f['experience']['raw_states'])\n",
    "        state = np.array(f['experience']['states'])\n",
    "        action = np.array(f['experience']['actions'])\n",
    "        reward = np.array(f['experience']['rewards'])    \n",
    "        advantage = np.array(f['experience']['advantages'])    \n",
    "\n",
    "    raw_state_updated = raw_state[np.where(reward != 0.0)[0]]\n",
    "    state_updated = state[np.where(reward != 0.0)[0]]\n",
    "    action_updated = action[np.where(reward != 0.0)[0]]\n",
    "    reward_updated = reward[np.where(reward != 0.0)[0]]\n",
    "    advantage_updated = advantage[np.where(reward != -0.1)[0]]\n",
    "    \n",
    "    master_raw_state = np.concatenate([master_raw_state, raw_state_updated], axis =0)\n",
    "    master_state = np.concatenate([master_state, state_updated], axis =0)\n",
    "    master_action = np.concatenate([master_action, action_updated], axis =0)\n",
    "    master_reward = np.concatenate([master_reward, reward_updated], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f\"summary_experience_preset_start\", 'w') as f:\n",
    "    f.create_group('experience')\n",
    "    f['experience'].create_dataset('raw_states', data=master_raw_state)\n",
    "    f['experience'].create_dataset('states', data=master_state)\n",
    "    f['experience'].create_dataset('actions', data=master_action)\n",
    "    f['experience'].create_dataset('rewards', data=master_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with h5py.File(f\"experience_data/{file}\", 'r+') as f:\n",
    "        raw_state = np.array(f['experience']['raw_states'])\n",
    "        state = np.array(f['experience']['states'])\n",
    "        action = np.array(f['experience']['actions'])\n",
    "        reward = np.array(f['experience']['rewards'])    \n",
    "        advantage = np.array(f['experience']['advantages'])    \n",
    "\n",
    "    raw_state_updated = raw_state[np.where(reward != 0.0)[0]]\n",
    "    state_updated = state[np.where(reward != 0.0)[0]]\n",
    "    action_updated = action[np.where(reward != 0.0)[0]]\n",
    "    reward_updated = reward[np.where(reward != 0.0)[0]]\n",
    "    advantage_update = advantage[np.where(reward != -0.1)[0]]\n",
    "\n",
    "#     with h5py.File(f\"experience_data/experiment_no_draw_{file}\", 'w') as f:\n",
    "#         f.create_group('experience')\n",
    "#         f['experience'].create_dataset('raw_states', data=raw_state_updated)\n",
    "#         f['experience'].create_dataset('states', data=state_updated)\n",
    "#         f['experience'].create_dataset('actions', data=action_updated)\n",
    "#         f['experience'].create_dataset('rewards', data=reward_updated)\n",
    "#         f['experience'].create_dataset('advantages', data=advantage_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
