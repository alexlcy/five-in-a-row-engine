{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "0. Improve model to 50% accuracy\n",
    "1. Data Preprocessing (3 layer structure) [DONE]\n",
    "2. Data Preprocessing (5 layer structure)\n",
    "3. Building agent for the deep learning [Consider valid move]\n",
    "4. Reading the reinforcement learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import aim\n",
    "from aim.tensorflow import AimCallback \n",
    "from aim import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148883, 8, 8)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_files_X = sorted([\"game_data/\" + file for file in os.listdir(\"game_data/\") if file.startswith(\"master_mat\")])\n",
    "raw_X = np.concatenate([np.load(file) for file in mat_files_X])\n",
    "raw_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148883, 8, 8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_files_Y = sorted([\"game_data/\" + file for file in os.listdir(\"game_data/\") if file.startswith(\"master_move\")])\n",
    "raw_Y = np.concatenate([np.load(file) for file in mat_files_Y])\n",
    "raw_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Raw_X_full', raw_X)\n",
    "np.save('Raw_Y_full', raw_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "# No numba time: 13:52\n",
    "@jit()\n",
    "def potential_open_moves(game_state):\n",
    "\n",
    "    mat = np.copy(game_state)\n",
    "\n",
    "    master_X_open_self = []\n",
    "    master_X_open_oppo = []\n",
    "\n",
    "    for search_num in np.arange(4,1,-1):\n",
    "        X_open_self = np.zeros((8,8))\n",
    "        X_open_oppo = np.zeros((8,8))\n",
    "        X_record_self = np.zeros((8,8))\n",
    "        X_record_oppo = np.zeros((8,8))\n",
    "\n",
    "        # Did not consider open and close siutation\n",
    "        m = 8\n",
    "        n=8\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "\n",
    "                if j + search_num+1 <= m:\n",
    "                    sideway = mat[i][j:j+(search_num)]\n",
    "                    if np.sum(sideway) ==search_num:\n",
    "                        X_record_self[i][j:j+search_num] = 1\n",
    "\n",
    "                        if mat[i][j-1] == 0:\n",
    "                            X_open_self[i][j-1] = 1\n",
    "                        if  mat[i][j+(search_num)] == 0:\n",
    "                            X_open_self[i][j+(search_num)] = 1\n",
    "\n",
    "                    if np.sum(sideway) == -search_num:\n",
    "                        X_record_oppo[i][j:j+search_num] = 1\n",
    "\n",
    "                        if mat[i][j-1] == 0:\n",
    "                            X_open_oppo[i][j-1] = 1\n",
    "                        if  mat[i][j+(search_num)] == 0:\n",
    "                            X_open_oppo[i][j+(search_num)] = 1\n",
    "\n",
    "                if i + search_num+1 <= m:\n",
    "                    vert = mat[:,j][i:i+(search_num)]\n",
    "                    if np.sum(vert) == search_num:\n",
    "                        X_record_self[:,j][i:i+search_num] = 1\n",
    "\n",
    "                        if mat[i-1][j] == 0:\n",
    "                            X_open_self[i-1][j] = 1\n",
    "                        if mat[i+(search_num)][j] == 0:\n",
    "                            X_open_self[i+(search_num)][j] = 1\n",
    "\n",
    "                    if np.sum(vert) == -search_num:\n",
    "                        X_record_oppo[:,j][i:i+search_num] = 1\n",
    "\n",
    "                        if mat[i-1][j] == 0:\n",
    "                            X_open_oppo[i-1][j] = 1\n",
    "                        if mat[i+(search_num)][j] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j] = 1\n",
    "\n",
    "\n",
    "                if j + search_num+1 <= m and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j+y] for x in range(search_num) for y in range(search_num) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_self[i+k][j+k] = 1\n",
    "\n",
    "\n",
    "                        if mat[i-1][j-1] == 0:\n",
    "                            X_open_self[i-1][j-1] = 1\n",
    "                        if mat[i+(search_num)][j+(search_num)] == 0:\n",
    "                            X_open_self[i+(search_num)][j+(search_num)] = 1\n",
    "\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_oppo[i+k][j+k] = 1\n",
    "\n",
    "                        if mat[i-1][j-1] == 0:\n",
    "                            X_open_oppo[i-1][j-1] = 1\n",
    "                        if mat[i+(search_num)][j+(search_num)] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j+(search_num)] = 1\n",
    "\n",
    "                if j - search_num >= 0 and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j-y] for x in range(search_num) for y in range(search_num) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_self[i+k][j-k] = 1\n",
    "\n",
    "                        if mat[i-1][j+1] == 0:\n",
    "                            X_open_self[i-1][j-1] = 1\n",
    "                        if  mat[i+(search_num)][j-(search_num)] == 0:\n",
    "                            X_open_self[i+(search_num)][j-(search_num)] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_oppo[i+k][j-k] = 1\n",
    "\n",
    "\n",
    "                        if mat[i-1][j+1] == 0:\n",
    "                            X_open_oppo[i-1][j+1] = 1\n",
    "                        if mat[i+(search_num)][j-(search_num)] == 0:\n",
    "                            X_open_oppo[i+(search_num)][j-(search_num)] = 1\n",
    "\n",
    "        i_axis = list(np.where(X_record_self==1)[0]) + list(np.where(X_record_oppo==1)[0])\n",
    "        j_axis = list(np.where(X_record_self==1)[1]) + list(np.where(X_record_oppo==1)[1])\n",
    "\n",
    "        for i,j in zip(i_axis, j_axis):\n",
    "            mat[i][j] = 0\n",
    "\n",
    "        master_X_open_self.append(np.copy(X_open_self))\n",
    "        master_X_open_oppo.append(np.copy(X_open_oppo))\n",
    "    return master_X_open_self + master_X_open_oppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "# No numba time: 13:52\n",
    "@jit()\n",
    "def potential_open_moves(game_state):\n",
    "\n",
    "    mat = np.copy(game_state)\n",
    "\n",
    "    master_X_open_self = []\n",
    "    master_X_open_oppo = []\n",
    "\n",
    "    for search_num in np.arange(4,1,-1):\n",
    "        X_open_self = np.zeros((8,8))\n",
    "        X_open_oppo = np.zeros((8,8))\n",
    "        X_record_self = np.zeros((8,8))\n",
    "        X_record_oppo = np.zeros((8,8))\n",
    "\n",
    "        # Did not consider open and close siutation\n",
    "        m = 8\n",
    "        n=8\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "\n",
    "                if j + search_num+1 <= m:\n",
    "                    sideway = mat[i][j:j+(search_num+1)]\n",
    "                    if np.sum(sideway) ==search_num:\n",
    "                        X_record_self[i][j:j+search_num] = 1\n",
    "\n",
    "                        if mat[i][j] == 0:\n",
    "                            X_open_self[i][j] = 1\n",
    "                        if j+(search_num+1) < m and mat[i][j+(search_num+1)] == 0:\n",
    "                            X_open_self[i][j+(search_num+1)] = 1\n",
    "\n",
    "                    if np.sum(sideway) == -search_num:\n",
    "                        X_record_oppo[i][j:j+search_num] = 1\n",
    "\n",
    "                        if mat[i][j] == 0:\n",
    "                            X_open_oppo[i][j] = 1\n",
    "                        if j+(search_num+1) < m and mat[i][j+(search_num+1)] == 0:\n",
    "                            X_open_oppo[i][j+(search_num+1)] = 1\n",
    "\n",
    "                if i + search_num+1 <= m:\n",
    "                    vert = mat[:,j][i:i+(search_num+1)]\n",
    "                    if np.sum(vert) == search_num:\n",
    "                        X_record_self[:,j][i:i+search_num] = 1\n",
    "\n",
    "                        if mat[i][j] == 0:\n",
    "                            X_open_self[i][j] = 1\n",
    "                        if i+(search_num+1) < m and mat[i+(search_num+1)][j] == 0:\n",
    "                            X_open_self[i+(search_num+1)][j] = 1\n",
    "\n",
    "                    if np.sum(vert) == -search_num:\n",
    "                        X_record_oppo[:,j][i:i+search_num] = 1\n",
    "\n",
    "                        if mat[i][j] == 0:\n",
    "                            X_open_oppo[i][j] = 1\n",
    "                        if i+(search_num+1) < m and mat[i+(search_num+1)][j] == 0:\n",
    "                            X_open_oppo[i+(search_num+1)][j] = 1\n",
    "\n",
    "\n",
    "                if j + search_num+1 <= m and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j+y] for x in range(search_num+1) for y in range(search_num+1) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_self[i+k][j+k] = 1\n",
    "\n",
    "\n",
    "                        if mat[i][j] == 0:\n",
    "                            X_open_self[i][j] = 1\n",
    "                        if i+(search_num+1)<m and j+(search_num+1)<m  and mat[i+(search_num+1)][j+(search_num+1)] == 0:\n",
    "                            X_open_self[i+(search_num+1)][j+(search_num+1)] = 1\n",
    "\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_oppo[i+k][j+k] = 1\n",
    "\n",
    "                        if mat[i][j] == 0:\n",
    "                            X_open_oppo[i][j] = 1\n",
    "                        if i+(search_num+1)<m and j+(search_num+1)<m  and mat[i+(search_num+1)][j+(search_num+1)] == 0:\n",
    "                            X_open_oppo[i+(search_num+1)][j+(search_num+1)] = 1\n",
    "\n",
    "                if j - search_num >= 0 and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j-y] for x in range(search_num+1) for y in range(search_num+1) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_self[i+k][j-k] = 1\n",
    "\n",
    "                        if mat[i][j] == 0:\n",
    "                            X_open_self[i][j] = 1\n",
    "                        if i+(search_num+1)<m and j-(search_num+1)<m and mat[i+(search_num+1)][j-(search_num+1)] == 0:\n",
    "                            X_open_self[i+(search_num+1)][j-(search_num+1)] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_record_oppo[i+k][j-k] = 1\n",
    "\n",
    "\n",
    "                        if mat[i][j] == 0:\n",
    "                            X_open_oppo[i][j] = 1\n",
    "                        if i+(search_num+1)<m and j-(search_num+1)<m  and mat[i+(search_num+1)][j-(search_num+1)] == 0:\n",
    "                            X_open_oppo[i+(search_num+1)][j-(search_num+1)] = 1\n",
    "\n",
    "        i_axis = list(np.where(X_record_self==1)[0]) + list(np.where(X_record_oppo==1)[0])\n",
    "        j_axis = list(np.where(X_record_self==1)[1]) + list(np.where(X_record_oppo==1)[1])\n",
    "\n",
    "        for i,j in zip(i_axis, j_axis):\n",
    "            mat[i][j] = 0\n",
    "\n",
    "        master_X_open_self.append(np.copy(X_open_self))\n",
    "        master_X_open_oppo.append(np.copy(X_open_oppo))\n",
    "    return master_X_open_self + master_X_open_oppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "# No numba time: 13:52\n",
    "@jit()\n",
    "def break_down_layers(game_state):\n",
    "    mat = np.copy(game_state)\n",
    "\n",
    "    master_X_open_self = []\n",
    "    master_X_open_oppo = []\n",
    "\n",
    "    for search_num in np.arange(4,0,-1):\n",
    "        X_open_self = np.zeros((8,8))\n",
    "        X_open_oppo = np.zeros((8,8))\n",
    "\n",
    "        # Did not consider open and close siutation\n",
    "        m = 8\n",
    "        n=8\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                if j + search_num+1 <= m:\n",
    "                    sideway = mat[i][j:j+(search_num)]\n",
    "                    if np.sum(sideway) ==search_num:\n",
    "                        X_open_self[i][j:j+search_num] = 1\n",
    "                    if np.sum(sideway) == -search_num:\n",
    "                        X_open_oppo[i][j:j+search_num] = 1\n",
    "\n",
    "                if i + search_num+1 <= m:\n",
    "                    vert = mat[:,j][i:i+(search_num)]\n",
    "                    if np.sum(vert) == search_num:\n",
    "                        X_open_self[:,j][i:i+search_num] = 1\n",
    "                    if np.sum(vert) == -search_num:\n",
    "                        X_open_oppo[:,j][i:i+search_num] = 1\n",
    "\n",
    "                if j + search_num+1 <= m and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j+y] for x in range(search_num) for y in range(search_num) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_self[i+k][j+k] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_oppo[i+k][j+k] = 1\n",
    "\n",
    "                if j - search_num >= 0 and i + search_num+1 <= n:\n",
    "                    diag = np.array([mat[i+x][j-y] for x in range(search_num) for y in range(search_num) if x == y])\n",
    "                    if np.sum(diag) == search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_self[i+k][j-k] = 1\n",
    "                    if np.sum(diag) == -search_num:\n",
    "                        for k in range(search_num):\n",
    "                            X_open_oppo[i+k][j-k] = 1\n",
    "\n",
    "        i_axis = list(np.where(X_open_self==1)[0]) + list(np.where(X_open_oppo==1)[0])\n",
    "        j_axis = list(np.where(X_open_self==1)[1]) + list(np.where(X_open_oppo==1)[1])\n",
    "\n",
    "        for i,j in zip(i_axis, j_axis):\n",
    "            mat[i][j] = 0\n",
    "            \n",
    "\n",
    "        master_X_open_self.append(np.copy(X_open_self))\n",
    "        master_X_open_oppo.append(np.copy(X_open_oppo))\n",
    "    return master_X_open_self + master_X_open_oppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(raw_X, raw_Y):\n",
    "    total_X = []\n",
    "    for i in tqdm(range(1, len(raw_X))):\n",
    "        input_X = raw_X[i]\n",
    "        layer_my_move = np.array(input_X > 0).astype(int)\n",
    "        layer_oppo_move = np.array(input_X < 0).astype(int)\n",
    "        layer_valid_move = np.array(input_X == 0).astype(int)\n",
    "        #layers_break_down = break_down_layers(input_X)\n",
    "        layers_break_down = potential_open_moves(input_X)\n",
    "        layer_last_move = raw_Y[i-1]\n",
    "        layer_zeros = np.zeros((8,8))\n",
    "        layer_ones = np.ones((8,8))\n",
    "        \n",
    "        final_X = np.dstack([layer_my_move, layer_oppo_move, layer_last_move, layer_valid_move+layer_zeros+layer_ones] + layers_break_down)\n",
    "        final_X = np.expand_dims(final_X, axis = 0)\n",
    "        total_X.append(final_X)\n",
    "    X = np.vstack(total_X)\n",
    "    Y = raw_Y[1:]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb61a338bea740e3ab3210822dee7c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77348.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X,Y = preprocess_data(raw_X, raw_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 8, 8, 10)\n",
      "(61878, 8, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "X,Y = shuffle(X,Y)\n",
    "X_train = X[:int(len(X)*0.8)]\n",
    "X_test = X[int(len(X)*0.8):]\n",
    "Y_train = Y[:int(len(X)*0.8)]\n",
    "Y_test = Y[int(len(X)*0.8):]\n",
    "print(X_train.shape)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 64)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],64)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, data_directory, samples):\n",
    "        self.data_directory = data_directory\n",
    "        self.samples = samples\n",
    "        self.files = set(file_name for file_name, index in samples)    1\n",
    "        self.num_samples = None\n",
    "\n",
    "    def get_num_samples(self, batch_size=128, num_classes=19 * 19):    2\n",
    "        if self.num_samples is not None:\n",
    "            return self.num_samples\n",
    "        else:\n",
    "            self.num_samples = 0\n",
    "            for X, y in self._generate(batch_size=batch_size,\n",
    "                                       num_classes=num_classes):\n",
    "                self.num_samples += X.shape[0]\n",
    "            return self.num_samples\n",
    "        \n",
    "    def _generate(self, batch_size, num_classes):\n",
    "        for zip_file_name in self.files:\n",
    "            file_name = zip_file_name.replace('.tar.gz', '') + 'train'\n",
    "            base = self.data_directory + '/' + file_name + '_features_*.npy'\n",
    "            for feature_file in glob.glob(base):\n",
    "                label_file = feature_file.replace('features', 'labels')\n",
    "                x = np.load(feature_file)\n",
    "                y = np.load(label_file)\n",
    "                x = x.astype('float32')\n",
    "                y = to_categorical(y.astype(int), num_classes)\n",
    "                while x.shape[0] >= batch_size:\n",
    "                    x_batch, x = x[:batch_size], x[batch_size:]\n",
    "                    y_batch, y = y[:batch_size], y[batch_size:]\n",
    "                    yield x_batch, y_batch    \n",
    "                    \n",
    "    def generate(self, batch_size=128, num_classes=19 * 19):\n",
    "        while True:\n",
    "            for item in self._generate(batch_size, num_classes):\n",
    "                yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45853, 8, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "#X_train = X_train.reshape(X_train.shape[0],8,8,1)\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 64)\n",
    "#X_test = X_test.reshape(X_test.shape[0],8,8,1)\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],64)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GomokuNet(tf.keras.Model):\n",
    "    def __init__(self,nums_class=64):\n",
    "        super(GomokuNet,self).__init__()\n",
    "        self.model = tf.keras.layers.Conv2D(48,(3,3), input_shape=(8,8,10),strides=(1,1))\n",
    "        self.res_layer_1 = self.ResNet_build(48, 2, strides=1)\n",
    "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc_model = tf.keras.layers.Dense(nums_class)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.model(inputs)\n",
    "        x = self.res_layer_1(x)\n",
    "        x = self.avg_pool(x) \n",
    "        x = self.fc_model(x)\n",
    "        return x\n",
    "    \n",
    "    def res_net_block(input_data, filters, conv_size):\n",
    "        x = tf.keras.layers.Conv2D(filters, conv_size, activation='relu', padding='same')(input_data)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Add()([x, input_data])\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    def ResNet_build(self,filter_nums,block_nums,strides=1):\n",
    "        build_model = tf.keras.models.Sequential()\n",
    "        build_model.add(ResBlock(filter_nums,strides))\n",
    "        for _ in range(1,block_nums):\n",
    "            build_model.add(ResBlock(filter_nums,strides=1))\n",
    "        return build_model\n",
    "    \n",
    "\n",
    "class ResBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filter_nums, strides=1, residual_path=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(filter_nums,(3,3),strides=strides,padding='same')\n",
    "        self.bn_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_relu = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(filter_nums,(3,3),strides=1,padding='same')\n",
    "        self.bn_2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        if strides !=1:\n",
    "            self.block = tf.keras.models.Sequential()\n",
    "            self.block.add(tf.keras.layers.Conv2D(filter_nums,(1,1),strides=strides))\n",
    "        else:\n",
    "            self.block = lambda x:x\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x, training=training)\n",
    "        x = self.act_relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x,training=training)\n",
    "\n",
    "        identity = self.block(inputs)\n",
    "        outputs = tf.keras.layers.add([x,identity])\n",
    "        outputs = tf.nn.relu(outputs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_session = Session(experiment='Gomuko-4planes-6layers-normalshape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GomokuNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (4,4), activation='relu', input_shape=(8,8,10), padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (4,4), activation='relu',  padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', ddpadding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    #The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (2,2), activation='relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "#     # 512 neuron hidden layer\n",
    "#     tf.keras.layers.Dense(256, activation='relu'),\n",
    "    \n",
    "    # Last layer of model\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train', X_train)\n",
    "np.save('Y_train', Y_train)\n",
    "np.save('X_test', X_test)\n",
    "np.save('Y_test', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39601920"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "61878* 8* 8* 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "242/242 [==============================] - 54s 221ms/step - loss: 4.1190 - accuracy: 0.0412 - val_loss: 4.1153 - val_accuracy: 0.0291\n",
      "Epoch 2/30\n",
      "242/242 [==============================] - 52s 213ms/step - loss: 3.7396 - accuracy: 0.1176 - val_loss: 3.4165 - val_accuracy: 0.1688\n",
      "Epoch 3/30\n",
      "242/242 [==============================] - 51s 213ms/step - loss: 3.2820 - accuracy: 0.2001 - val_loss: 2.9351 - val_accuracy: 0.2614\n",
      "Epoch 4/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 2.8900 - accuracy: 0.2625 - val_loss: 2.5409 - val_accuracy: 0.3017\n",
      "Epoch 5/30\n",
      "242/242 [==============================] - 52s 213ms/step - loss: 2.6043 - accuracy: 0.3160 - val_loss: 2.3684 - val_accuracy: 0.3448\n",
      "Epoch 6/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 2.3652 - accuracy: 0.3630 - val_loss: 2.1358 - val_accuracy: 0.3680\n",
      "Epoch 7/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 2.1951 - accuracy: 0.3933 - val_loss: 2.1747 - val_accuracy: 0.3846\n",
      "Epoch 8/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 2.0662 - accuracy: 0.4210 - val_loss: 2.0393 - val_accuracy: 0.3977\n",
      "Epoch 9/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 1.9663 - accuracy: 0.4395 - val_loss: 1.9795 - val_accuracy: 0.3965\n",
      "Epoch 10/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.8700 - accuracy: 0.4653 - val_loss: 1.9864 - val_accuracy: 0.3975\n",
      "Epoch 11/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.7927 - accuracy: 0.4820 - val_loss: 2.1278 - val_accuracy: 0.3961\n",
      "Epoch 12/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.7219 - accuracy: 0.4975 - val_loss: 2.0413 - val_accuracy: 0.4028\n",
      "Epoch 13/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.6534 - accuracy: 0.5167 - val_loss: 2.5075 - val_accuracy: 0.3846\n",
      "Epoch 14/30\n",
      "242/242 [==============================] - 52s 213ms/step - loss: 1.5991 - accuracy: 0.5311 - val_loss: 2.0583 - val_accuracy: 0.3998\n",
      "Epoch 15/30\n",
      "242/242 [==============================] - 51s 212ms/step - loss: 1.5512 - accuracy: 0.5431 - val_loss: 2.1203 - val_accuracy: 0.3778\n",
      "Epoch 16/30\n",
      "242/242 [==============================] - 52s 213ms/step - loss: 1.5013 - accuracy: 0.5551 - val_loss: 2.2614 - val_accuracy: 0.4020\n",
      "Epoch 17/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 1.4538 - accuracy: 0.5645 - val_loss: 2.1349 - val_accuracy: 0.4001\n",
      "Epoch 18/30\n",
      "242/242 [==============================] - 53s 217ms/step - loss: 1.4516 - accuracy: 0.5731 - val_loss: 2.2644 - val_accuracy: 0.3926\n",
      "Epoch 19/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.4089 - accuracy: 0.5885 - val_loss: 2.5625 - val_accuracy: 0.3878\n",
      "Epoch 20/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.3565 - accuracy: 0.5954 - val_loss: 2.2314 - val_accuracy: 0.4030\n",
      "Epoch 21/30\n",
      "242/242 [==============================] - 52s 214ms/step - loss: 1.3440 - accuracy: 0.6062 - val_loss: 2.6566 - val_accuracy: 0.4106\n",
      "Epoch 22/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.3046 - accuracy: 0.6099 - val_loss: 2.5617 - val_accuracy: 0.4081\n",
      "Epoch 23/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.3090 - accuracy: 0.6196 - val_loss: 2.3302 - val_accuracy: 0.4097\n",
      "Epoch 24/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.2505 - accuracy: 0.6286 - val_loss: 2.2990 - val_accuracy: 0.4008\n",
      "Epoch 25/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.2236 - accuracy: 0.6390 - val_loss: 2.2433 - val_accuracy: 0.4048\n",
      "Epoch 26/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.1791 - accuracy: 0.6435 - val_loss: 3.0798 - val_accuracy: 0.3994\n",
      "Epoch 27/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.1536 - accuracy: 0.6511 - val_loss: 2.3325 - val_accuracy: 0.3948\n",
      "Epoch 28/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.1645 - accuracy: 0.6613 - val_loss: 2.5290 - val_accuracy: 0.4020\n",
      "Epoch 29/30\n",
      "242/242 [==============================] - 52s 216ms/step - loss: 1.1075 - accuracy: 0.6629 - val_loss: 2.9861 - val_accuracy: 0.4050\n",
      "Epoch 30/30\n",
      "242/242 [==============================] - 52s 215ms/step - loss: 1.0951 - accuracy: 0.6698 - val_loss: 3.0628 - val_accuracy: 0.4050\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    Y_train, \n",
    "                    epochs=30,\n",
    "                    batch_size=256,\n",
    "                    validation_data = (X_test, Y_test), \n",
    "                    verbose = 1, \n",
    "                   #callbacks=[AimCallback(aim_session)]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/allpattern_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/allpattern_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/allpattern_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = tf.keras.models.load_model('saved_model/allpattern_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tempfile\n",
    "import keras_util\n",
    "import tensorflow as tf\n",
    "from encoder.base import get_encoder_by_name\n",
    "encoder = get_encoder_by_name('allpattern', 8)\n",
    "from tensorflow.keras.models import load_model, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File('experience_data/first_experiment.hdf5','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f.create_group('encoder')\n",
    "f['encoder'].attrs['name'] = 'allpattern'\n",
    "f['encoder'].attrs['board_width'] = 8\n",
    "f['encoder'].attrs['board_height'] = 8\n",
    "f.create_group('model')\n",
    "model_loaded.save(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexlo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"first_experiment.hdf5\" (mode r+)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.File('experience_data/first_experiment.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tf.convert_to_tensor(X_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
